{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e3e890-a7f3-4109-a78e-964a7ab37076",
   "metadata": {},
   "source": [
    "# Face Recognition Using Sianese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e69a25-4728-49cd-86e7-56e93c7580a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "!pip install opencv-python matplotlib scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8099fa44-f957-4924-b66b-595b10da7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import combinations\n",
    "import csv\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99768740-6b34-4db4-ae15-5dd0ae25bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca8a94c2-f1ea-4603-8550-16adb3dfd481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2785f2c2-2b82-4116-8fec-cdc0d0768e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAIRS = []\n",
    "ROOT = './lfw'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac5c66c-b81d-4b0d-9a16-b0cd197af2a7",
   "metadata": {},
   "source": [
    "### Create Pairs for the Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935546f2-26e0-43d3-83d7-96e1a822246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_similarity_pairs():\n",
    "    list_dir = list(os.listdir(ROOT))\n",
    "    output = []\n",
    "    \n",
    "    for i, faces in enumerate(list_dir):\n",
    "        file_path = os.path.join(ROOT, faces)\n",
    "        for pair in combinations(os.listdir(file_path), 2):\n",
    "            output.append([faces, pair[0], faces, pair[1], 1])\n",
    "\n",
    "    return output;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c13e7-b69a-4e73-9bff-69c0f1b026d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dissimilarity_pairs():\n",
    "    list_dir = list(os.listdir(ROOT))\n",
    "    output = []\n",
    "\n",
    "    for i, faces_name in enumerate(list_dir):\n",
    "        list_face1 = os.listdir(os.path.join(ROOT, faces_name))\n",
    "        \n",
    "        for j in range(i + 1, min(i+40, len(list_dir))):\n",
    "            list_face2 = os.listdir(os.path.join(ROOT, list_dir[j]))\n",
    "            output.append([faces_name, list_face1[0], list_dir[j], list_face2[0], 0])\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1bd0f-ba10-4a6a-b263-96c2b24a0262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs():\n",
    "    return create_similarity_pairs() + create_dissimilarity_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0476a7c4-c00f-44e5-ac7c-11f5dafebf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAIRS = create_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef202282-cebb-4374-bd92-d6ed373757bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAIRS[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9839286f-01e6-4f26-88a9-7eb8bd933369",
   "metadata": {},
   "source": [
    "# Convert the data into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49d712ec-f9b4-488a-87fc-c82bfe623a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the result of pairs into csv\n",
    "with open('dataset.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(PAIRS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26e9f08a-c232-427e-b7c8-d34942d1b267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input1_name</th>\n",
       "      <th>input1_filename</th>\n",
       "      <th>input2_name</th>\n",
       "      <th>input2_filename</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>Aaron_Peirsol_0001.jpg</td>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>Aaron_Peirsol_0003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>Aaron_Peirsol_0001.jpg</td>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>Aaron_Peirsol_0004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>Aaron_Peirsol_0002.jpg</td>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>Aaron_Peirsol_0003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>Aaron_Peirsol_0002.jpg</td>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>Aaron_Peirsol_0004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>Aaron_Peirsol_0003.jpg</td>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>Aaron_Peirsol_0004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input1_name         input1_filename    input2_name  \\\n",
       "0  Aaron_Peirsol  Aaron_Peirsol_0001.jpg  Aaron_Peirsol   \n",
       "1  Aaron_Peirsol  Aaron_Peirsol_0001.jpg  Aaron_Peirsol   \n",
       "2  Aaron_Peirsol  Aaron_Peirsol_0002.jpg  Aaron_Peirsol   \n",
       "3  Aaron_Peirsol  Aaron_Peirsol_0002.jpg  Aaron_Peirsol   \n",
       "4  Aaron_Peirsol  Aaron_Peirsol_0003.jpg  Aaron_Peirsol   \n",
       "\n",
       "          input2_filename  similarity  \n",
       "0  Aaron_Peirsol_0003.jpg           1  \n",
       "1  Aaron_Peirsol_0004.jpg           1  \n",
       "2  Aaron_Peirsol_0003.jpg           1  \n",
       "3  Aaron_Peirsol_0004.jpg           1  \n",
       "4  Aaron_Peirsol_0004.jpg           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df = pd.read_csv('./dataset.csv')\n",
    "image_df.columns = ['input1_name', 'input1_filename', 'input2_name', 'input2_filename', 'similarity']\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45341cb-30b5-42a8-9217-ad4f8fb3157d",
   "metadata": {},
   "source": [
    "### Read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be6295aa-4c60-4662-a37a-c9f4f7c35e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img, target_size):\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a38a93a-a59c-47d9-9f7c-52f194f83a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess_images(df, target_size=(180, 180)):\n",
    "    images1 = []\n",
    "    images2 = []\n",
    "    similarity = df['similarity'].to_numpy()\n",
    "    for index, row in df.iterrows():\n",
    "        path1 = os.path.join(ROOT, row['input1_name'], row['input1_filename'])\n",
    "        path2 = os.path.join(ROOT, row['input2_name'], row['input2_filename'])\n",
    "        \n",
    "        img1 = cv2.imread(path1)\n",
    "        img2 = cv2.imread(path2)\n",
    "\n",
    "        img1 = preprocess_image(img1, target_size)\n",
    "        img2 = preprocess_image(img2, target_size)\n",
    "            \n",
    "        images1.append(img1)\n",
    "        images2.append(img2)\n",
    "    \n",
    "    return np.array(images1), np.array(images2), siimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112e8691-4159-454f-ad46-5bf9e5a5c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1, input2, similarity = read_and_preprocess_images(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d65f40c-8bf9-4c17-b73f-f521078172f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34d2e302-a374-46fe-a198-21058622d02f",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b12025-5224-4886-8284-032594b4d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the base network\n",
    "def create_base_network(input_shape):\n",
    "    input = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(input)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "input_shape = input1_images.shape[1:]  # Assuming all images have the same shape\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "# Create the inputs\n",
    "input_a = layers.Input(shape=input_shape)\n",
    "input_b = layers.Input(shape=input_shape)\n",
    "\n",
    "# Generate the feature vectors for the two images\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "# Compute the Euclidean distance between the feature vectors\n",
    "distance = layers.Lambda(lambda tensors: tf.sqrt(tf.reduce_sum(tf.square(tensors[0] - tensors[1]), axis=1, keepdims=True)))(\n",
    "    [processed_a, processed_b])\n",
    "\n",
    "# Define the model\n",
    "model = Model([input_a, input_b], distance)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3ee91-c73b-47f3-9a98-adfb34e1774a",
   "metadata": {},
   "source": [
    "# Split the test and train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddd74419-a868-4eb2-85b0-a7667c25a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the train-test split\n",
    "train_df, test_df = train_test_split(image_df, test_size=0.2, stratify=image_df['similarity'], random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3904e9-7eea-4518-b60f-792276885bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
